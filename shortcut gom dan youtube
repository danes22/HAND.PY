import cv2
import mediapipe as mp
import pyautogui


mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)


cap = cv2.VideoCapture(0)

while True:  
    ret, frame = cap.read()
    if not ret:
        break   
    
    frame = cv2.flip(frame, 1)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb)
    
    if result.multi_hand_landmarks:
        for handLms in result.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, handLms, mp_hands.HAND_CONNECTIONS)
            
            lm = handLms.landmark
            h, w, _ = frame.shape
            finger_y = [int(lm[i].y * h) for i in [8, 12, 16, 20]]
            thumb_y = int(lm[4].y * h)
            thumb_x = int(lm[4].x * w)
            
            
            if all(y > lm[0].y * h for y in finger_y):  
                pyautogui.press("k")
                cv2.putText(frame, "Play/Pause", (50,50), cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)
            
            elif thumb_y < lm[0].y * h:  
                pyautogui.press("up")
                cv2.putText(frame, "Volume UP", (50,100), cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)
            
            elif thumb_y > lm[0].y * h:  
                pyautogui.press("down")
                cv2.putText(frame, "Volume DOWN", (50,150), cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)
            
            elif thumb_x > lm[0].x * w:  
                pyautogui.press("shift, n")
                cv2.putText(frame, "Next video", (50,200), cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,255),2)
            
            elif thumb_x < lm[0].x * w:  
                pyautogui.press("shift, p")
                cv2.putText(frame, "Previous video", (50,250), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,0),2)
    
    cv2.imshow("Gesture Music Control", frame)
    
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break   


cap.release()
cv2.destroyAllWindows()
